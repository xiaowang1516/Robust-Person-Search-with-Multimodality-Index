## Robust-Person-Search-with-Multimodality-Index
# Abstract
  Person search with one portrait, which attempts to search the targets in arbitrary scenes using one portrait image at a time, is an essential yet unexplored problem in the multimedia field. Existing approaches, which predominantly depend on the visual information of persons, cannot solve problems when there are variations in the person's appearance caused by complex environments and changes in pose, makeup, and clothing. In contrast to existing methods, in this paper, we propose an associative multimodality index for person search with face, body, and voice information. In the offline stage, an associative network is proposed to learn the relationships among face, body, and voice information. It can adaptively estimate the weights of each embedding to construct an appropriate representation. The multimodality index can be built by using these representations, which exploit the face and voice as long-term keys and the body appearance as a short-term connection. In the online stage, through the multimodality association in the index, we can retrieve all targets depending only on the facial features of the query portrait. Furthermore, to evaluate our multimodality search framework and facilitate related research, we construct the Cast Search in Movies with Voice (CSM-V) dataset, a large-scale benchmark that contains 127K annotated voices corresponding to tracklets from 192 movies. According to extensive experiments on the CSM-V dataset, the proposed multimodality person search framework outperforms the state-of-the-art methods.
  [Motivation web]
# Contributions
- To facilitate the research on multimodality for person search, we construct the Cast Search in Movies with Voice ([CSM-V](https://pan.baidu.com/s/18W-NsgTFLTNFdAdNAbtJfw)) dataset based on the [CSM dataset](https://pan.baidu.com/s/1JG30kPTWxJmf1saA0e6CLQ#list/path=%2F). CSM-V contains 127K annotated voices corresponding to tracklets from 192 movies.
- We propose a cross-model of auditory and visual perception for person search with one portrait, which combines visual and voice representation to mine identity consistency in complex and variable environments.
- An associative network is proposed to associate the multimodality from vision and voice. It can adaptively estimate the weights of each embedding to construct an appropriate representation in the identity index.
# Framework
  [Framework web]


